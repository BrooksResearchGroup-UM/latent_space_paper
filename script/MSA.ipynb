{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training binary shape:  (33972, 352, 21)\n",
      "Testing binary shape:  (1091, 352, 21)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "from sys import exit\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "file_name = \"../data/PF01494_MSA.fasta\"\n",
    "query_seq_id = \"B8M9J8\" #TropB\n",
    "\n",
    "# Read all the sequences into a dictionary\n",
    "id_list = []\n",
    "seq_list = []\n",
    "seq_dict = {}\n",
    "for record in SeqIO.parse(file_name, \"fasta\"):\n",
    "    ID = record.id\n",
    "    id_list.append(ID)\n",
    "    seq_list.append(str(record.seq.upper()))\n",
    "    seq_dict[ID] = str(record.seq.upper())\n",
    "\n",
    "FMO = []\n",
    "for idx, (seq, ID) in enumerate(zip(seq_list, id_list)):\n",
    "    FMO.append(SeqRecord(Seq(seq), id=ID, description=\"\")) \n",
    "with open(\"../data/PF01494_MSA_nodes.fasta\", \"w\") as handle:\n",
    "    SeqIO.write(FMO, handle, \"fasta\")\n",
    "    \n",
    "# Remove gaps in the query sequences\n",
    "query_seq = seq_dict[query_seq_id] ## with gaps\n",
    "idx = [ s == \"-\" or s == \".\" for s in query_seq]\n",
    "for k in seq_dict.keys():\n",
    "    seq_dict[k] = [seq_dict[k][i] for i in range(len(seq_dict[k])) if idx[i] == False]\n",
    "query_seq = seq_dict[query_seq_id] ## without gaps\n",
    "\n",
    "# Remove sequences with too many gaps\n",
    "len_query_seq = len(query_seq)\n",
    "seq_id = list(seq_dict.keys())\n",
    "num_gaps = []\n",
    "for k in seq_id:\n",
    "    num_gaps.append(seq_dict[k].count(\"-\") + seq_dict[k].count(\".\"))\n",
    "    if seq_dict[k].count(\"-\") + seq_dict[k].count(\".\") > 0.2*len_query_seq:\n",
    "        seq_dict.pop(k)\n",
    "\n",
    "with open(\"../data/encoding/seq_dict.pkl\", 'wb') as file_handle:\n",
    "     pickle.dump(seq_dict, file_handle)\n",
    "\n",
    "# Convert aa type into num 0-20\n",
    "aa = ['R', 'H', 'K',\n",
    "      'D', 'E',\n",
    "      'S', 'T', 'N', 'Q',\n",
    "      'C', 'G', 'P',\n",
    "      'A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W']\n",
    "aa_index = {}\n",
    "aa_index['-'] = 0\n",
    "aa_index['.'] = 0\n",
    "i = 1\n",
    "for a in aa:\n",
    "    aa_index[a] = i\n",
    "    i += 1\n",
    "with open(\"../data/encoding/aa_index.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(aa_index, file_handle)\n",
    "    \n",
    "seq_msa = []\n",
    "keys_list = []\n",
    "for k in seq_dict.keys():\n",
    "    if seq_dict[k].count('X') > 0 or seq_dict[k].count('Z') or seq_dict[k].count('O')> 0:\n",
    "        continue    \n",
    "    seq_msa.append([aa_index[s] for s in seq_dict[k]])\n",
    "    keys_list.append(k)    \n",
    "seq_msa = np.array(seq_msa)\n",
    "\n",
    "training_keys_list = keys_list[0:33972]\n",
    "testing_keys_list = keys_list[33972:]\n",
    "\n",
    "# Training keys\n",
    "with open(\"../data/encoding/keys_list.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(training_keys_list, file_handle)\n",
    "\n",
    "# Testing keys\n",
    "with open(\"../data/encoding/t_keys_list.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(testing_keys_list, file_handle)\n",
    "\n",
    "# Split the training and testing datasets\n",
    "training_seq_msa = seq_msa[0:33972,:]\n",
    "testing_seq_msa = seq_msa[33972:,:]\n",
    "\n",
    "# Reweight sequences\n",
    "# note: only reweighted sequences are used for training.\n",
    "# seq_msa.shape[0]: number of sequences\n",
    "# seq_msa.shape[1]: sequence length\n",
    "seq_weight = np.zeros(training_seq_msa.shape)\n",
    "for j in range(training_seq_msa.shape[1]):\n",
    "    aa_type, aa_counts = np.unique(training_seq_msa[:,j], return_counts = True)\n",
    "    num_type = len(aa_type)\n",
    "    aa_dict = {}\n",
    "    for a in aa_type:\n",
    "        aa_dict[a] = aa_counts[list(aa_type).index(a)]\n",
    "    for i in range(training_seq_msa.shape[0]):\n",
    "        seq_weight[i,j] = (1.0/num_type) * (1.0/aa_dict[seq_msa[i,j]])\n",
    "tot_weight = np.sum(seq_weight)\n",
    "seq_weight = seq_weight.sum(1) / tot_weight \n",
    "with open(\"../data/encoding/seq_weight.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(seq_weight, file_handle)\n",
    "\n",
    "# Testing sequence weight\n",
    "t_seq_weight = np.ones(testing_seq_msa.shape[0]) / testing_seq_msa.shape[0]\n",
    "t_seq_weight = t_seq_weight.astype(np.float32)\n",
    "with open(\"../data/encoding/t_seq_weight.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(t_seq_weight, file_handle)\n",
    "\n",
    "# Remove positions where too many sequences have gaps\n",
    "pos_idx = []\n",
    "for i in range(training_seq_msa.shape[1]):\n",
    "    if np.sum(seq_msa[:,i] == 0) <= seq_msa.shape[0]*0.2:\n",
    "        pos_idx.append(i)\n",
    "with open(\"../data/encoding/seq_pos_idx.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(pos_idx, file_handle)\n",
    "    \n",
    "training_seq_msa = training_seq_msa[:, np.array(pos_idx)]\n",
    "testing_seq_msa = testing_seq_msa[:, np.array(pos_idx)]\n",
    "with open(\"../data/encoding/seq_msa.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(training_seq_msa, file_handle)\n",
    "with open(\"../data/encoding/t_seq_msa.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(testing_seq_msa, file_handle)\n",
    "\n",
    "# Change aa numbering into binary\n",
    "K = 21 # num of classes of aa\n",
    "D = np.identity(K)\n",
    "training_num_seq = training_seq_msa.shape[0]\n",
    "testing_num_seq = testing_seq_msa.shape[0]\n",
    "len_seq_msa = training_seq_msa.shape[1]\n",
    "training_seq_msa_binary = np.zeros((training_num_seq, len_seq_msa, K))\n",
    "testing_seq_msa_binary = np.zeros((testing_num_seq, len_seq_msa, K))\n",
    "for i in range(training_num_seq):\n",
    "    training_seq_msa_binary[i,:,:] = D[training_seq_msa[i]]\n",
    "for j in range(testing_num_seq):\n",
    "    testing_seq_msa_binary[j,:,:] = D[testing_seq_msa[j]]\n",
    "\n",
    "# Training binary\n",
    "with open(\"../data/encoding/seq_msa_binary.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(training_seq_msa_binary, file_handle)\n",
    "\n",
    "# Print train_seq_msa_binary shape\n",
    "print('Training binary shape: ', training_seq_msa_binary.shape)\n",
    "\n",
    "# Testing binary\n",
    "with open(\"../data/encoding/t_seq_msa_binary.pkl\", 'wb') as file_handle:\n",
    "    pickle.dump(testing_seq_msa_binary, file_handle) \n",
    "\n",
    "# Print test_seq_msa_binary shape\n",
    "print('Testing binary shape: ', testing_seq_msa_binary.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
